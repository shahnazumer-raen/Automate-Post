{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate Tech Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle of LLM Chat Model\n",
    "\n",
    "- Understanding the business Statement\n",
    "- creating data collection\n",
    "- creating vectorestore\n",
    "- add collection to vectorstore\n",
    "- Using RAG to retrieve data from Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business statement\n",
    "- when developing a technical product, writing techinical blog post can help users to get started by following post and seeing how to set. now the problem is how can we ensure the post reach to the community?\n",
    "\n",
    "- In open source, a common pratice is to retrieve data from webpage in combination of code and convert to text.\n",
    "\n",
    "# Problem statement\n",
    " How can we leverage open source tools to do outreach with the community?\n",
    "\n",
    "  - One way is to spread the word and connect with community is through social media, like twitter, Linkedin.\n",
    "  - With the rise of Artificial Intellengence, we can automate the process of generating blogs that are enticing and will encourage users to try a tech product.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    " - Source - https://numpy.org/doc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries , Langchain, OpenAI, OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from qdrant_client import models, QdrantClient\n",
    "import qdrant_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use OpenAIEmbeddings so we have to get the OpenAI API Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings using Qdrant Vectorstore\n",
    "Qdrant is a vector database & vector similarity search engine\n",
    "\n",
    " - First we want to create a Qdrant vector store and seed it with some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create qdrant client\n",
    "\n",
    "os.environ['QDRANT_HOST']\n",
    "os.environ[\"QDRANT_API_KEY\"]\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    os.getenv(\"QDRANT_HOST\"),\n",
    "    api_key=os.getenv(\"QDRANT_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "file=\"numpy.txt\"\n",
    "data=\"\"\n",
    "\n",
    "with open(file,'r') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the text into chunks\n",
    "#create a function to return chunks\n",
    "def get_chunks(text):\n",
    "    text_splitter=CharacterTextSplitter(\n",
    "        separator= \"\\n\",\n",
    "        chunk_size=700,\n",
    "        chunk_overlap=100,\n",
    "         # second chunk start  character from 800, overlap is used to stop loosing chunk \n",
    "        length_function=len\n",
    "    )\n",
    "\n",
    "    chunks=text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the chunks for the data\n",
    "texts=get_chunks(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3606"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new  collection and naming it.\n",
    "\n",
    "vectors_config=models.VectorParams(\n",
    "    # depends on model, we can google dimension. 1536 for openai\n",
    "    # we are using openai embedding, for that size is 1536\n",
    "    size=1536,\n",
    "    distance=models.Distance.COSINE)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"numpy\",\n",
    "    vectors_config=vectors_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\automate-tech-post\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# if we want to use any other embedding, we need to change size\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vector_store = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=\"numpy\",\n",
    "    embeddings=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6ce0d3327a174d29b01bd4b49bfdfa61',\n",
       " 'ce5b689de17746cdbf5c1a2336286cee',\n",
       " '77a0b30fdd5c428f840c9b0f51436c53',\n",
       " '5e9ef869acb14293a66583c855e26f05',\n",
       " '41208f494f484ca0b98a65ac610368fb',\n",
       " 'cb08df9e8c2f490e9beabbc3314875b5',\n",
       " '81ebc32802fa447d8741224bff0f86b6']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add chunks to vector store\n",
    "vector_store.add_texts(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our RAG retriever\n",
    "The next step is to perform a relevancy search. The user query is converted to a vector representation and matched with the vector databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try passing a question through to a these vectorstore objects\n",
    "\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "     \n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LCEL\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary to generate a blog about\n",
    "\n",
    "This blog  is a tutorial about using NumPy to solve static equilibrium problems in three-dimensional space. Readers will learn how to represent points, vectors, and moments with NumPy, find the normal of vectors, and use NumPy for matrix calculations. The tutorial covers the application of Newton's second law to simple examples of force\n",
    "vectors and introduces more complex cases involving reaction forces and moments. The post also discusses the use of NumPy functions in more varied problems, including kinetic problems and different dimensions, here are some few questions we can ask our model to generate the response;\n",
    "\n",
    " - how to train a simple feed-forward neural network from scratch using NumPy to classify handwritten MNIST digits?\n",
    " - what is concept of masked arrays in NumPy and their usefulness in handling missing or invalid data?\n",
    " - Linear algebra on n-dimensional arrays\n",
    " - NumPy to solve static equilibrium problems in three-dimensional space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To train a simple feed-forward neural network from scratch using NumPy to classify handwritten MNIST digits, you need to follow these steps:\\n\\n1. Load the MNIST dataset, which contains 60,000 training images and 10,000 test images, along with their corresponding labels.\\n2. Split the training images into a training set and a validation set.\\n3. Initialize the weights of the neural network.\\n4. Define the activation functions and their derivatives that will be used in the network.\\n5. Implement a function for forward pass and backward pass in the network.\\n6. Train the model in batches using stochastic gradient descent (SGD), updating the weights based on the gradients computed during backpropagation.\\n7. Test the model's accuracy on the validation set.\\n8. Finally, predict the classes of the images in the test set and print the accuracy of the model's predictions.\\n\\nBy following these steps, you can build and train a simple feed-forward neural network from scratch using NumPy to classify handwritten MNIST digits.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"how to train a simple feed-forward neural network from scratch using NumPy to classify handwritten MNIST digits?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The concept of masked arrays in NumPy is the combination of a standard numpy.ndarray and a mask. A mask is either nomask, indicating that no value of the associated array is invalid, or an array of booleans that determines for each element of the associated array whether the value is valid or not. Masked arrays are useful in handling missing or invalid data."
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream(\"what is concept of masked arrays in NumPy and their usefulness in handling missing or invalid data?\"):\n",
    "    print(chunk, end=\"\", flush=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear algebra is an important topic in the data science domain. It is particularly relevant when working with n-dimensional arrays, which are collections of data represented with numbers. Linear algebra allows for efficient computations on these arrays, which is especially important in machine learning and deep learning models that require large amounts of data. By using vectorized or matrix operations, the performance and accuracy of these models can be improved."
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream(\"Linear algebra on n-dimensional arrays\"):\n",
    "    print(chunk, end=\"\", flush=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
