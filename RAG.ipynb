{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate Tech Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll examine a brief introduction to Retrieval Augmented Generation using Langchain.\n",
    "\n",
    "We'll Also Be Using the Langchain Expression Language to build our solutions. LCEL is a production ready style of building and prototyping chains. with automatic async and built-in parallelization, LCEL ensures you're ready for production with very little developer-side lift!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle of LLM Chat Model\n",
    "\n",
    "- Understanding the business Statement\n",
    "- creating data collection\n",
    "- creating vectorestore\n",
    "- add collection to vectorstore\n",
    "- Using RAG to retrieve data from Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business statement\n",
    "- when developing a technical product, writing techinical blog post can help users to get started by following post and seeing how to set. now the problem is how can we ensure the post reach to the community?\n",
    "- In open source, a common pratice is to retrieve data from webpage in combination of code and convert to text.\n",
    "- How can we leverage open source tools to do outreach with the community?\n",
    "- One way is to spread the word and connect with community is through social media, like twitter, Linkedin.\n",
    "- With the rise of Artificial Intellengence, we can automate the process of generating blogs that are enticing and will encourage users to try a tech product.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Domain\n",
    "\n",
    " - The domain i've selected today is about Numpy - it's fairly niche topic.\n",
    " - Source - https://numpy.org/doc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    " Model - this allow us to specify our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templete\n",
    "\n",
    "Since we need to pass in user-defined questions to our RAG chain, wwe want to set up a simple templete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Parser\n",
    "\n",
    "If we look at our LLM- we'll notice that it's outputs are Message objects-we can convert the response into a str by chaining a StrOutputParser at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings using Qdrant Vectorstore\n",
    "Qdrant is a vector database & vector similarity search engine\n",
    "\n",
    " - First we want to create a Qdrant vector store and seed it with some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Qdrant\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from qdrant_client import models, QdrantClient\n",
    "import qdrant_client\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create qdrant client\n",
    "\n",
    "os.environ['QDRANT_HOST']\n",
    "os.environ[\"QDRANT_API_KEY\"]\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    os.getenv(\"QDRANT_HOST\"),\n",
    "    api_key=os.getenv(\"QDRANT_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "file=\"numpy.txt\"\n",
    "data=\"\"\n",
    "\n",
    "with open(file,'r') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll use the naive solution of the CharacterTextSplitter first, which will simply split our text  and measure chunk length by number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the text into chunks\n",
    "#create a function to return chunks\n",
    "def get_chunks(text):\n",
    "    text_splitter=CharacterTextSplitter(\n",
    "        separator= \"\\n\",\n",
    "        chunk_size=700,\n",
    "        chunk_overlap=100,\n",
    "         # second chunk start  character from 800, overlap is used to stop loosing chunk \n",
    "        length_function=len\n",
    "    )\n",
    "\n",
    "    chunks=text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the chunks for the data\n",
    "texts=get_chunks(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3606"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new  collection and naming it.\n",
    "\n",
    "vectors_config=models.VectorParams(\n",
    "    # depends on model, we can google dimension. 1536 for openai\n",
    "    # we are using openai embedding, for that size is 1536\n",
    "    size=1536,\n",
    "    distance=models.Distance.COSINE)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"numpy\",\n",
    "    vectors_config=vectors_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Model & API Keys\n",
    "\n",
    "Now that we've chunked our documents, we'll need to vectorize them and move them into a Vectorstore - a place that will associate Vectors with Text Chunks.\n",
    "\n",
    "We'll be using OpenAI Embeddings and API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\automate-tech-post\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# if we want to use any other embedding, we need to change size\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vector_store = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=\"numpy\",\n",
    "    embeddings=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9784ad6af04d4298a5cd1f0ec0d0ba26',\n",
       " 'b4e1afd4bca44f47961c46b9f88a48ef',\n",
       " 'ba781bdaf9a64445ba554c529be18eb0',\n",
       " 'f7291fa80d034ed29a0802f7bb9e71b3',\n",
       " '8a93bb6e9fc64103911eb0655274593b',\n",
       " '55c7ac3ec4ed49e6a88412fa5fe17f59',\n",
       " '9466a568b2274e8ab93c6dae8a9b0213']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add chunks to vector store\n",
    "vector_store.add_texts(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Genaration with LangChain - Simple Implementation\n",
    "We've built a fully-fledged knowledge base, We'll now implement a simple RAG chain to boost the performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever\n",
    "\n",
    "Now that we have a VectorStore - We'll need to connect it to a retriever. Luckily, this is a straight forward process with LangChain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\automate-tech-post\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "     \n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With LCEL - Building a chain has never been easier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary to generate a blog about\n",
    "\n",
    "This blog  is a tutorial about using NumPy to solve static equilibrium problems in three-dimensional space. Readers will learn how to represent points, vectors, and moments with NumPy, find the normal of vectors, and use NumPy for matrix calculations. The tutorial covers the application of Newton's second law to simple examples of force\n",
    "vectors and introduces more complex cases involving reaction forces and moments. The post also discusses the use of NumPy functions in more varied problems, including kinetic problems and different dimensions, here are some few questions we can ask our model to generate the response;\n",
    "\n",
    " - how to train a simple feed-forward neural network from scratch using NumPy to classify handwritten MNIST digits?\n",
    " - what is concept of masked arrays in NumPy and their usefulness in handling missing or invalid data?\n",
    " - Linear algebra on n-dimensional arrays\n",
    " - NumPy to solve static equilibrium problems in three-dimensional space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To train a simple feed-forward neural network from scratch using NumPy to classify handwritten MNIST digits, you need to follow the steps mentioned in the context. \\n\\n1. Initialize the weights.\\n2. Define activation functions and their derivatives.\\n3. Implement functions for forward pass and backward pass.\\n4. Train the model in batches using Stochastic Gradient Descent (SGD) and update the weights.\\n5. Test the model on the validation set.\\n6. Predict on the test data and print the accuracy.\\n\\nBy following these steps, you can build and train a simple feed-forward neural network using NumPy to classify handwritten MNIST digits.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"how to train a simple feed-forward neural network from scratch using NumPy to classify handwritten MNIST digits?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The concept of masked arrays in NumPy is the combination of a standard ndarray and a mask. A mask is either nomask, indicating that no value of the associated array is invalid, or an array of booleans that determines for each element of the associated array whether the value is valid or not. Masked arrays are useful in handling missing or invalid data by allowing the user to easily identify and manipulate these values."
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream(\"what is concept of masked arrays in NumPy and their usefulness in handling missing or invalid data?\"):\n",
    "    print(chunk, end=\"\", flush=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear algebra on n-dimensional arrays refers to the use of linear algebra operations, such as matrix multiplication and vector addition, on arrays with multiple dimensions. This is particularly relevant in the context of machine learning and deep learning models, which often require large amounts of data for optimal performance. As the amount of data increases, performing operations on individual scalars becomes inefficient, and vectorized or matrix operations are needed to compute efficiently. Linear algebra provides the necessary tools and techniques for manipulating and analyzing n-dimensional arrays."
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream(\"Linear algebra on n-dimensional arrays\"):\n",
    "    print(chunk, end=\"\", flush=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
